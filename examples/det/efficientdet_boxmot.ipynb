{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install effdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-25 20:18:18.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mboxmot.utils.torch_utils\u001b[0m:\u001b[36mselect_device\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mYolo Tracking v11.0.4 ðŸš€ Python-3.11.5 torch-2.2.2MPS\u001b[0m\n",
      "\u001b[32m2024-10-25 20:18:18.130\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mboxmot.appearance.reid_model_factory\u001b[0m:\u001b[36mload_pretrained_weights\u001b[0m:\u001b[36m183\u001b[0m - \u001b[32m\u001b[1mLoaded pretrained weights from osnet_x0_25_msmt17.pt\u001b[0m\n",
      "2024-10-25 20:18:19.273 Python[18715:112823] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/mikel.brostrom/boxmot/examples/det/efficientdet_boxmot.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mikel.brostrom/boxmot/examples/det/efficientdet_boxmot.ipynb#W1sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m vid \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mVideoCapture(\u001b[39m0\u001b[39m)  \u001b[39m# or 'path/to/your.avi'\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mikel.brostrom/boxmot/examples/det/efficientdet_boxmot.ipynb#W1sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mikel.brostrom/boxmot/examples/det/efficientdet_boxmot.ipynb#W1sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39m# Capture frame-by-frame\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mikel.brostrom/boxmot/examples/det/efficientdet_boxmot.ipynb#W1sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     ret, frame \u001b[39m=\u001b[39m vid\u001b[39m.\u001b[39;49mread()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mikel.brostrom/boxmot/examples/det/efficientdet_boxmot.ipynb#W1sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     \u001b[39m# If ret is False, it means we have reached the end of the video\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mikel.brostrom/boxmot/examples/det/efficientdet_boxmot.ipynb#W1sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ret:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import torchvision.ops as ops\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from effdet import create_model\n",
    "from effdet.config import get_efficientdet_config\n",
    "from boxmot import BotSort\n",
    "from boxmot.utils.ops import letterbox\n",
    "\n",
    "\n",
    "# Load EfficientDet model\n",
    "device = torch.device('mps')  # Use 'cuda' if you have a GPU\n",
    "\n",
    "model_name = 'tf_efficientdet_d0'  # You can choose a different variant like 'tf_efficientdet_d3'\n",
    "config = get_efficientdet_config(model_name)\n",
    "model = create_model(model_name, bench_task='predict', pretrained=True).to(device)\n",
    "model.eval()\n",
    "\n",
    "# Initialize the tracker\n",
    "tracker = BotSort(\n",
    "    reid_weights=Path('osnet_x0_25_msmt17.pt'),  # Path to ReID model\n",
    "    device=device,  # Use CPU for inference\n",
    "    half=False\n",
    ")\n",
    "\n",
    "input_size = config.image_size\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Open the video file\n",
    "vid = cv2.VideoCapture(0)  # or 'path/to/your.avi'\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    # If ret is False, it means we have reached the end of the video\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Apply letterbox resizing\n",
    "    frame_letterbox, ratio, (dw, dh) = letterbox(frame, new_shape=input_size, auto=False, scaleFill=True)\n",
    "    \n",
    "    # Preprocess frame for EfficientDet (resize and normalize)\n",
    "    frame_tensor = preprocess(frame_letterbox).unsqueeze(0).to(device)\n",
    "\n",
    "    # Perform detection\n",
    "    with torch.no_grad():\n",
    "        detections = model(frame_tensor)[0]\n",
    "                \n",
    "    # Assuming detections is shaped [100, 6], with [x1, y1, x2, y2, confidence, class]\n",
    "    confidence_threshold = 0.5\n",
    "    \n",
    "    # Filter detections based on confidence threshold\n",
    "    mask = detections[:, 4] >= confidence_threshold\n",
    "    filtered_dets = detections[mask]\n",
    "\n",
    "    # Rescale coordinates from letterbox back to the original frame size\n",
    "    filtered_dets[:, 0] = (filtered_dets[:, 0] - dw) / ratio[0]\n",
    "    filtered_dets[:, 1] = (filtered_dets[:, 1] - dh) / ratio[1]\n",
    "    filtered_dets[:, 2] = (filtered_dets[:, 2] - dw) / ratio[0]\n",
    "    filtered_dets[:, 3] = (filtered_dets[:, 3] - dh) / ratio[1]\n",
    "\n",
    "    # Convert class to integer and stack results\n",
    "    dets = torch.cat((filtered_dets[:, :5], filtered_dets[:, 5].unsqueeze(1).int()), dim=1)\n",
    "\n",
    "    # Convert to numpy array (N X (x, y, x, y, conf, cls))\n",
    "    dets = dets.cpu().numpy()\n",
    "\n",
    "    # Update the tracker\n",
    "    res = tracker.update(dets, frame)  # --> M X (x, y, x, y, id, conf, cls, ind)\n",
    "\n",
    "    # Plot tracking results on the image\n",
    "    tracker.plot_results(frame, show_trajectories=True)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('BoXMOT + EfficientDet', frame)\n",
    "\n",
    "    # Simulate wait for key press to continue, press 'q' to exit\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boxmot-YDNZdsaB-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
